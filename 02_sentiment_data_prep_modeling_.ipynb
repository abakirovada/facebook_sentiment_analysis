{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e410e4f0-40f8-4a20-9690-f48f8f6d41ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "from langdetect import detect, DetectorFactory\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f6365e0-a5f8-44bd-90cd-19147e802cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2924, 19)\n",
      "Columns: ['post_url', 'post_text', 'post_label', 'number_of_likes', 'number_of_shares', 'number_of_comments', 'post_date', 'comment_text', 'comment_date', 'comment_reactions_count', 'comment_mode_types', 'post_target_region', 'post_language', 'comment_language', 'coal_topic/event_tag', 'season', 'comment_sentiment_label', 'sentiment_confidence', 'news_page_name']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_url</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_label</th>\n",
       "      <th>number_of_likes</th>\n",
       "      <th>number_of_shares</th>\n",
       "      <th>number_of_comments</th>\n",
       "      <th>post_date</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_date</th>\n",
       "      <th>comment_reactions_count</th>\n",
       "      <th>comment_mode_types</th>\n",
       "      <th>post_target_region</th>\n",
       "      <th>post_language</th>\n",
       "      <th>comment_language</th>\n",
       "      <th>coal_topic/event_tag</th>\n",
       "      <th>season</th>\n",
       "      <th>comment_sentiment_label</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>news_page_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.facebook.com/AzattykPlus/posts/252...</td>\n",
       "      <td>–≠–ª–µ–∫—Ç—Ä –∂–µ—Ç–∏—à—Å–∏–∑, –∫”©–º“Ø—Ä –∫—ã–º–±–∞—Ç - ”©–∫–º”©—Ç –∫–µ–ª—Å–∏–Ω</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-09-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>countrywide</td>\n",
       "      <td>Kyrgyz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high price</td>\n",
       "      <td>fall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Azattyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.facebook.com/AzattykPlus/posts/283...</td>\n",
       "      <td>–¢“Æ–®–¢“Æ–ö–¢”® –ö”®–ú“Æ–†–î“Æ–ù –¢–û–ù–ù–ê–°–´ 7 –ú–ò“¢ –°–û–ú–ì–û –ß–´–ö–¢–´</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-09-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Osh</td>\n",
       "      <td>Kyrgyz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high price</td>\n",
       "      <td>fall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Azattyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.facebook.com/AzattykPlus/posts/214...</td>\n",
       "      <td>–ö—ã–∑—ã–ª-–ö—ã—è —à–∞–∞—Ä—ã–Ω–¥–∞–≥—ã —Ü–µ–º–µ–Ω—Ç –∑–∞–≤–æ–¥—É–Ω—É–Ω –∂–∞–Ω—ã–Ω–¥–∞ ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-10-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Batken</td>\n",
       "      <td>Kyrgyz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>illegal coal mining</td>\n",
       "      <td>fall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Azattyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.facebook.com/AliToktakunov/posts/1...</td>\n",
       "      <td>–ö—ã–∑—ã–ª-–ö—ã—è —à–∞–∞—Ä—ã–Ω–¥–∞–≥—ã —Ü–µ–º–µ–Ω—Ç –∑–∞–≤–æ–¥—É–Ω—É–Ω –∂–∞–Ω—ã–Ω–¥–∞ ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-10-11</td>\n",
       "      <td>–ë–∏–π–ª–∏–∫—Ç–µ–≥–∏–ª–µ—Ä –∫–∞—Ä–∞–±–∞—Å–∞ —É—à—É–Ω–¥–∞–π –±–æ–ª–æ—Ç—Ç–∞, –±–∞—Ä–¥—ã–∫...</td>\n",
       "      <td>2011-10-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>text</td>\n",
       "      <td>Batken</td>\n",
       "      <td>Kyrgyz</td>\n",
       "      <td>Kyrgyz</td>\n",
       "      <td>illegal coal mining</td>\n",
       "      <td>fall</td>\n",
       "      <td>negative</td>\n",
       "      <td>high</td>\n",
       "      <td>Azattyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.facebook.com/groups/araba.kg/perma...</td>\n",
       "      <td>–ö—ã—Ä–≥—ã–∑—Å—Ç–∞–Ω.–°–æ“£–∫—É –±–∏—Ä –∞–ø—Ç–∞ –∏—á–∏–Ω–¥–µ –ö—ã—Ä–≥—ã–∑—Å—Ç–∞–Ω–¥–∞ ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-08-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>countrywide</td>\n",
       "      <td>Kyrgyz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high price</td>\n",
       "      <td>summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>araba.kg-avtobazar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            post_url  \\\n",
       "0  https://www.facebook.com/AzattykPlus/posts/252...   \n",
       "1  https://www.facebook.com/AzattykPlus/posts/283...   \n",
       "2  https://www.facebook.com/AzattykPlus/posts/214...   \n",
       "3  https://www.facebook.com/AliToktakunov/posts/1...   \n",
       "4  https://www.facebook.com/groups/araba.kg/perma...   \n",
       "\n",
       "                                           post_text post_label  \\\n",
       "0       –≠–ª–µ–∫—Ç—Ä –∂–µ—Ç–∏—à—Å–∏–∑, –∫”©–º“Ø—Ä –∫—ã–º–±–∞—Ç - ”©–∫–º”©—Ç –∫–µ–ª—Å–∏–Ω   negative   \n",
       "1        –¢“Æ–®–¢“Æ–ö–¢”® –ö”®–ú“Æ–†–î“Æ–ù –¢–û–ù–ù–ê–°–´ 7 –ú–ò“¢ –°–û–ú–ì–û –ß–´–ö–¢–´   negative   \n",
       "2  –ö—ã–∑—ã–ª-–ö—ã—è —à–∞–∞—Ä—ã–Ω–¥–∞–≥—ã —Ü–µ–º–µ–Ω—Ç –∑–∞–≤–æ–¥—É–Ω—É–Ω –∂–∞–Ω—ã–Ω–¥–∞ ...   negative   \n",
       "3  –ö—ã–∑—ã–ª-–ö—ã—è —à–∞–∞—Ä—ã–Ω–¥–∞–≥—ã —Ü–µ–º–µ–Ω—Ç –∑–∞–≤–æ–¥—É–Ω—É–Ω –∂–∞–Ω—ã–Ω–¥–∞ ...   negative   \n",
       "4  –ö—ã—Ä–≥—ã–∑—Å—Ç–∞–Ω.–°–æ“£–∫—É –±–∏—Ä –∞–ø—Ç–∞ –∏—á–∏–Ω–¥–µ –ö—ã—Ä–≥—ã–∑—Å—Ç–∞–Ω–¥–∞ ...   negative   \n",
       "\n",
       "   number_of_likes  number_of_shares  number_of_comments   post_date  \\\n",
       "0                0                 0                   0  2008-09-04   \n",
       "1                0                 0                   0  2008-09-14   \n",
       "2                0                 1                   0  2011-10-11   \n",
       "3                1                 0                   1  2011-10-11   \n",
       "4                0                 0                   0  2011-08-23   \n",
       "\n",
       "                                        comment_text comment_date  \\\n",
       "0                                                NaN          NaN   \n",
       "1                                                NaN          NaN   \n",
       "2                                                NaN          NaN   \n",
       "3  –ë–∏–π–ª–∏–∫—Ç–µ–≥–∏–ª–µ—Ä –∫–∞—Ä–∞–±–∞—Å–∞ —É—à—É–Ω–¥–∞–π –±–æ–ª–æ—Ç—Ç–∞, –±–∞—Ä–¥—ã–∫...   2011-10-11   \n",
       "4                                                NaN          NaN   \n",
       "\n",
       "   comment_reactions_count comment_mode_types post_target_region  \\\n",
       "0                      NaN                NaN        countrywide   \n",
       "1                      NaN                NaN                Osh   \n",
       "2                      NaN                NaN             Batken   \n",
       "3                      0.0               text             Batken   \n",
       "4                      NaN                NaN        countrywide   \n",
       "\n",
       "  post_language comment_language coal_topic/event_tag  season  \\\n",
       "0        Kyrgyz              NaN           high price    fall   \n",
       "1        Kyrgyz              NaN           high price    fall   \n",
       "2        Kyrgyz              NaN  illegal coal mining    fall   \n",
       "3        Kyrgyz           Kyrgyz  illegal coal mining    fall   \n",
       "4        Kyrgyz              NaN           high price  summer   \n",
       "\n",
       "  comment_sentiment_label sentiment_confidence      news_page_name  \n",
       "0                     NaN                  NaN             Azattyk  \n",
       "1                     NaN                  NaN             Azattyk  \n",
       "2                     NaN                  NaN             Azattyk  \n",
       "3                negative                 high             Azattyk  \n",
       "4                     NaN                  NaN  araba.kg-avtobazar  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset and inspect\n",
    "\n",
    "df = pd.read_csv('../data/kyrgyz_coal_dataset_cleaned.csv')\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dae996-a83f-4836-9522-f304ad89e5b5",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4075ce07-7592-4616-b962-349370e5c773",
   "metadata": {},
   "source": [
    "### 1. Cleaning Post and Comment Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05a61b10-84a6-448c-8449-4c2b232eee6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a7ebd3735a4e07a95c84145a34d557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2924 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc26eb4478de443d8b92fae51b89a81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2924 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post text language distribution:\n",
      "post_lang_detect\n",
      "ru    2896\n",
      "mk      17\n",
      "bg      11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Comment text language distribution:\n",
      "comment_lang_detect\n",
      "ru         2094\n",
      "tl          599\n",
      "mk           78\n",
      "bg           66\n",
      "en           39\n",
      "unknown      25\n",
      "uk           21\n",
      "tr            2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example of comments detected as Russian:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>–ò—Ç, –∞–≤–∞–ª–∞–π(.—É—Ä–æ).–±–µ—Ä–µ—Ç –∫–µ—Ä–±–µ–Ω –∂—É—Ä–æ –±–µ—Ä–µ—Ç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>–∫–∞—Ä–∞–ø–∞–π—ã–º, —ç–ª –±–∏—Ä–∏ –±–∏—Ä–∏ –º–µ–Ω–µ–Ω –∫—ã—Ä—ã–ª—ã—à–±–∞—Å–∞ –±–æ–ª–¥—É</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>–ö–∞–π—Ä–∞–Ω –ö—ã—Ä–≥—ã–∑ –∫–∞–ª–∫—ã–º..—á–∞–Ω –∂—É—Ç–∫–∞–Ω –≥–∞–∑ –∂—É—Ç–∫–∞–Ω –∫–æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>–≠—á –∫–∞–Ω–¥–∞–π –∫—Ä—ã—à–∞—Å—ã –∂–æ–∫ —ç–ª–µ –∏—à—Ç–µ—Ç–∏–ø –∂–∞—Ç—ã—à–∞—Ç –∂—É–º—É...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>–®–∞–π–ª–æ–æ–¥–æ–Ω  –∫–∏–π–∏–Ω –∫–æ—Ä–æ–±—É–∑ —Ü–µ–Ω–∞–Ω—ã.—à–∞–π–ª–æ–æ —Ä–µ–∫–ª–∞–º–∞—Å—ã</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment_text\n",
       "2428           –ò—Ç, –∞–≤–∞–ª–∞–π(.—É—Ä–æ).–±–µ—Ä–µ—Ç –∫–µ—Ä–±–µ–Ω –∂—É—Ä–æ –±–µ—Ä–µ—Ç\n",
       "2467    –∫–∞—Ä–∞–ø–∞–π—ã–º, —ç–ª –±–∏—Ä–∏ –±–∏—Ä–∏ –º–µ–Ω–µ–Ω –∫—ã—Ä—ã–ª—ã—à–±–∞—Å–∞ –±–æ–ª–¥—É\n",
       "2516  –ö–∞–π—Ä–∞–Ω –ö—ã—Ä–≥—ã–∑ –∫–∞–ª–∫—ã–º..—á–∞–Ω –∂—É—Ç–∫–∞–Ω –≥–∞–∑ –∂—É—Ç–∫–∞–Ω –∫–æ...\n",
       "924   –≠—á –∫–∞–Ω–¥–∞–π –∫—Ä—ã—à–∞—Å—ã –∂–æ–∫ —ç–ª–µ –∏—à—Ç–µ—Ç–∏–ø –∂–∞—Ç—ã—à–∞—Ç –∂—É–º—É...\n",
       "2716   –®–∞–π–ª–æ–æ–¥–æ–Ω  –∫–∏–π–∏–Ω –∫–æ—Ä–æ–±—É–∑ —Ü–µ–Ω–∞–Ω—ã.—à–∞–π–ª–æ–æ —Ä–µ–∫–ª–∞–º–∞—Å—ã"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example of comments detected as Russian:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>–ö”©–º“Ø—Ä! —á—ã–∫–∫–∞–Ω –ù–∞—Ä—ã–Ω–¥–∞ –æ—Ç—É–Ω —Ç–∞—Ä—Ç—ã—à –ö–∞—Ä–∞-–ö–µ—á–µ –∫–µ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>–ë—ã–π—ã–ª, ”©–ª–∫”©–¥”© –∫”©–º“Ø—Ä —Ç–∞—Ä—Ç—ã—à—Ç—ã–≥—ã –æ—Ä—É–Ω –∞–ª–±–∞–π–±—ã? –ë...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>–û—à! –æ–±–ª—É—Å—É–Ω–¥–∞ 30 –∂–µ—Ä–≥–µ –∞—Ä–∑–∞–Ω–¥–∞—Ç—ã–ª–≥–∞–Ω –∫”©–º“Ø—Ä —Å–∞—Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>–ñ—É–º–≥–∞–ª–¥—ã–Ω –ê—Ä–∞–ª –∞–π–º–∞–≥—ã–Ω–¥–∞–≥—ã –ö–æ–∫–æ-–ú–µ—Ä–µ–Ω –¥–∞—Ä—ã—è—Å—ã–Ω...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>–ñ–£–ú–ì–ê–õ–î–ê–ì–´. –ú–ò“¢-–ö–£–® –ê–ô–´–õ–´–ù–´–ù –¢–£–†–ì–£–ù–î–ê–†–´ –ê–ô–ú–ê–ö–¢...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              post_text\n",
       "2273  –ö”©–º“Ø—Ä! —á—ã–∫–∫–∞–Ω –ù–∞—Ä—ã–Ω–¥–∞ –æ—Ç—É–Ω —Ç–∞—Ä—Ç—ã—à –ö–∞—Ä–∞-–ö–µ—á–µ –∫–µ...\n",
       "1411  –ë—ã–π—ã–ª, ”©–ª–∫”©–¥”© –∫”©–º“Ø—Ä —Ç–∞—Ä—Ç—ã—à—Ç—ã–≥—ã –æ—Ä—É–Ω –∞–ª–±–∞–π–±—ã? –ë...\n",
       "1469  –û—à! –æ–±–ª—É—Å—É–Ω–¥–∞ 30 –∂–µ—Ä–≥–µ –∞—Ä–∑–∞–Ω–¥–∞—Ç—ã–ª–≥–∞–Ω –∫”©–º“Ø—Ä —Å–∞—Ç...\n",
       "204   –ñ—É–º–≥–∞–ª–¥—ã–Ω –ê—Ä–∞–ª –∞–π–º–∞–≥—ã–Ω–¥–∞–≥—ã –ö–æ–∫–æ-–ú–µ—Ä–µ–Ω –¥–∞—Ä—ã—è—Å—ã–Ω...\n",
       "2660  –ñ–£–ú–ì–ê–õ–î–ê–ì–´. –ú–ò“¢-–ö–£–® –ê–ô–´–õ–´–ù–´–ù –¢–£–†–ì–£–ù–î–ê–†–´ –ê–ô–ú–ê–ö–¢..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example of comments detected as English:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>thumb down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>thumb, up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>yuqoridegilaga insof bersin ollohim ilohimü§≤ü§≤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>thumb  up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>thumb! up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      comment_text\n",
       "458                                     thumb down\n",
       "2393                                     thumb, up\n",
       "507   yuqoridegilaga insof bersin ollohim ilohimü§≤ü§≤\n",
       "1642                                     thumb  up\n",
       "2202                                     thumb! up"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example of comments detected as Unknown:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>üëç,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>üëç,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     comment_text\n",
       "1614          :( \n",
       "1606           üëç,\n",
       "1758          :( \n",
       "306            :(\n",
       "2289           üëç,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure consistent and reproducible language detection\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Define detection function\n",
    "def detect_lang(text):\n",
    "    try:\n",
    "        return detect(str(text))\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Apply language detection to both post and comment texts\n",
    "tqdm.pandas()\n",
    "\n",
    "# Detect language in post_text\n",
    "df['post_lang_detect'] = df['post_text'].progress_apply(detect_lang)\n",
    "\n",
    "# Detect language in comment_text\n",
    "df['comment_lang_detect'] = df['comment_text'].progress_apply(detect_lang)\n",
    "\n",
    "# View results\n",
    "print(\"Post text language distribution:\")\n",
    "print(df['post_lang_detect'].value_counts())\n",
    "\n",
    "print(\"\\nComment text language distribution:\")\n",
    "print(df['comment_lang_detect'].value_counts())\n",
    "\n",
    "# Optionally show samples misclassified as Russian\n",
    "print(\"\\nExample of comments detected as Russian:\")\n",
    "display(df[df['comment_lang_detect'] == 'ru'][['comment_text']].sample(5, random_state=1))\n",
    "\n",
    "print(\"\\nExample of comments detected as Russian:\")\n",
    "display(df[df['post_lang_detect'] == 'ru'][['post_text']].sample(5, random_state=1))\n",
    "\n",
    "print(\"\\nExample of comments detected as English:\")\n",
    "display(df[df['comment_lang_detect'] == 'en'][['comment_text']].sample(5, random_state=1))\n",
    "\n",
    "print(\"\\nExample of comments detected as Unknown:\")\n",
    "display(df[df['comment_lang_detect'] == 'unknown'][['comment_text']].sample(5, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5441f73-eee4-4341-bf2f-0baccd325be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts shape: (2819, 3)\n",
      "Comments shape: (2162, 3)\n",
      "Shape after Kyrgyz-only filtering: (4981, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>–ê–ª–ª–∞. —Ä–∞–∞–∑—ã –±–æ–ª—Å—É–Ω —É—à—É–Ω–¥–∞–π –±–∞–ª–¥–∞—Ä –∫–æ–ø –±–æ–ª—Å—É–Ω –∞...</td>\n",
       "      <td>positive</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>–ö—ã—Ä–≥—ã–∑—Å—Ç–∞–Ω–¥–∞  —ç–Ω –∫—ã–º–±–∞—Ç –∫–µ–º—É—Ä –ë–∞—Ç–∫–µ–Ω –æ–±–ª—É—Å—É–Ω–¥–∞...</td>\n",
       "      <td>negative</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2405</th>\n",
       "      <td>–ê—Ç-–ë–∞—à—ã–¥–∞, –∫”©–º“Ø—Ä –∫”©–∑–¥”©–Ω —É—á—Ç—É –£—à—É–ª —Ç–∞–ø—Ç–∞ –ê—Ç-–ë–∞—à...</td>\n",
       "      <td>negative</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>–ö–∞—Ä–∞-–ö–µ—á–µ –∫”©–º“Ø—Ä –∫–µ–Ω–∏–Ω–∏–Ω –∫–æ–æ–ø—Å—É–∑–¥—É–∫ –∫—ã–∑–º–∞—Ç—ã–Ω—ã–Ω ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>–°—ã—Ä. —ç–º–µ—Å –≥–æ –º–µ–Ω –¥–µ–ª–µ –∞–π—ã–ª–¥–∞ –∂–∞—à–∞–π–º –∞–Ω–¥–∞–π –∫–∞—Ä–∞...</td>\n",
       "      <td>negative</td>\n",
       "      <td>comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label   source\n",
       "4245  –ê–ª–ª–∞. —Ä–∞–∞–∑—ã –±–æ–ª—Å—É–Ω —É—à—É–Ω–¥–∞–π –±–∞–ª–¥–∞—Ä –∫–æ–ø –±–æ–ª—Å—É–Ω –∞...  positive  comment\n",
       "2649  –ö—ã—Ä–≥—ã–∑—Å—Ç–∞–Ω–¥–∞  —ç–Ω –∫—ã–º–±–∞—Ç –∫–µ–º—É—Ä –ë–∞—Ç–∫–µ–Ω –æ–±–ª—É—Å—É–Ω–¥–∞...  negative     post\n",
       "2405  –ê—Ç-–ë–∞—à—ã–¥–∞, –∫”©–º“Ø—Ä –∫”©–∑–¥”©–Ω —É—á—Ç—É –£—à—É–ª —Ç–∞–ø—Ç–∞ –ê—Ç-–ë–∞—à...  negative     post\n",
       "262   –ö–∞—Ä–∞-–ö–µ—á–µ –∫”©–º“Ø—Ä –∫–µ–Ω–∏–Ω–∏–Ω –∫–æ–æ–ø—Å—É–∑–¥—É–∫ –∫—ã–∑–º–∞—Ç—ã–Ω—ã–Ω ...  negative     post\n",
       "4178  –°—ã—Ä. —ç–º–µ—Å –≥–æ –º–µ–Ω –¥–µ–ª–µ –∞–π—ã–ª–¥–∞ –∂–∞—à–∞–π–º –∞–Ω–¥–∞–π –∫–∞—Ä–∞...  negative  comment"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for manually labeled Kyrgyz content\n",
    "df_ky = df[\n",
    "    (df['comment_language'] == 'Kyrgyz') |\n",
    "    (df['post_language'] == 'Kyrgyz')\n",
    "].copy()\n",
    "\n",
    "# Kyrgyz posts\n",
    "posts_df = df_ky[df_ky['post_language'] == 'Kyrgyz'][['post_text', 'post_label']].dropna()\n",
    "posts_df = posts_df.rename(columns={'post_text': 'text', 'post_label': 'label'})\n",
    "posts_df['source'] = 'post'\n",
    "\n",
    "# Kyrgyz comments\n",
    "comments_df = df_ky[df_ky['comment_language'] == 'Kyrgyz'][['comment_text', 'comment_sentiment_label']].dropna()\n",
    "comments_df = comments_df.rename(columns={'comment_text': 'text', 'comment_sentiment_label': 'label'})\n",
    "comments_df['source'] = 'comment'\n",
    "\n",
    "# Show shapes to verify\n",
    "print(\"Posts shape:\", posts_df.shape)\n",
    "print(\"Comments shape:\", comments_df.shape)\n",
    "\n",
    "# Only combine if there's data\n",
    "combined_df = pd.concat([posts_df, comments_df], ignore_index=True)\n",
    "\n",
    "print(\"Shape after Kyrgyz-only filtering:\", combined_df.shape)\n",
    "combined_df.sample(5) if not combined_df.empty else print(\"Combined DataFrame is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ebc8e-5df0-44cf-a367-cf14744cb13f",
   "metadata": {},
   "source": [
    "### 2. Removing Emojis, Punctuation and Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b151ce29-8303-48db-8b42-5094d33ca331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape after cleaning: (4484, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>–ë–∏—à–∫–µ–∫:  —á–µ–∫—Ç”©”© –º–µ–Ω–µ–Ω —Å–∞—Ç—ã–ª–≥–∞–Ω –∞—Ä–∑–∞–Ω –∫”©–º“Ø—Ä –°—É—É...</td>\n",
       "      <td>negative</td>\n",
       "      <td>post</td>\n",
       "      <td>–±–∏—à–∫–µ–∫ —á–µ–∫—Ç”©”© —Å–∞—Ç—ã–ª–≥–∞–Ω –∞—Ä–∑–∞–Ω –∫”©–º“Ø—Ä —Å—É—É–∫ —Ç“Ø—à–∫”©–Ω...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>–ñ–æ–≥–æ—Ä–∫—É –ö–µ“£–µ—à –ñ–æ–≥–æ—Ä–∫—É —Å–æ—Ç—Ç—É–Ω –º–∏–ª–¥–µ—Ç–∏–Ω –∞—Ç–∫–∞—Ä—ã–ø ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>post</td>\n",
       "      <td>–∂–æ–≥–æ—Ä–∫—É –∫–µ“£–µ—à –∂–æ–≥–æ—Ä–∫—É —Å–æ—Ç—Ç—É–Ω –º–∏–ª–¥–µ—Ç–∏–Ω –∞—Ç–∫–∞—Ä—ã–ø ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>–ë–∏—à–∫–µ–∫–∫–µ! –∞—Ä–∑–∞–Ω –∫”©–º“Ø—Ä –∂–µ—Ç–∫–∏—Ä–∏–ª“Ø“Ø–¥”© ‚Äú–ö–∞—Ä–∞-–ö–µ—á–µ–¥...</td>\n",
       "      <td>positive</td>\n",
       "      <td>post</td>\n",
       "      <td>–±–∏—à–∫–µ–∫–∫–µ –∞—Ä–∑–∞–Ω –∫”©–º“Ø—Ä –∂–µ—Ç–∫–∏—Ä–∏–ª“Ø“Ø–¥”© –∫–∞—Ä–∞–∫–µ—á–µ–¥–µ–Ω ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>–ñ—É–º–≥–∞–ª —Ä–∞–π–æ–Ω—É–Ω–¥–∞ –∞–∑ –∫–∞–º—Å—ã–∑ —É–π-–±—É–ª–µ–ª–µ—Ä–≥–µ –∂–∞–ª–ø—ã ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>post</td>\n",
       "      <td>–∂—É–º–≥–∞–ª —Ä–∞–π–æ–Ω—É–Ω–¥–∞ –∞–∑ –∫–∞–º—Å—ã–∑ —É–π–±—É–ª–µ–ª–µ—Ä–≥–µ –∂–∞–ª–ø—ã 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>–ö–∞—Ä–∞-–ö–µ—á–µ–¥–µ–Ω –∫”©–º“Ø—Ä —Ç–∞—Ä—Ç–∫–∞–Ω –∂–µ–∫–µ –∏—à–∫–µ—Ä –∞–π–¥–æ–æ—á—É–ª...</td>\n",
       "      <td>negative</td>\n",
       "      <td>post</td>\n",
       "      <td>–∫–∞—Ä–∞–∫–µ—á–µ–¥–µ–Ω –∫”©–º“Ø—Ä —Ç–∞—Ä—Ç–∫–∞–Ω –∂–µ–∫–µ –∏—à–∫–µ—Ä –∞–π–¥–æ–æ—á—É–ª–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>–ö”©–º“Ø—Ä, —Ç–∞—à—ã–≥–∞–Ω –∞–π–¥–æ–æ—á—É–ª–∞—Ä –∏—à —Ç–∞—à—Ç–∞–¥—ã –ë–∏—à–∫–µ–∫ –∂—ã...</td>\n",
       "      <td>positive</td>\n",
       "      <td>post</td>\n",
       "      <td>–∫”©–º“Ø—Ä —Ç–∞—à—ã–≥–∞–Ω –∞–π–¥–æ–æ—á—É–ª–∞—Ä –∏—à —Ç–∞—à—Ç–∞–¥—ã –±–∏—à–∫–µ–∫ –∂—ã–ª...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>–ù–∞—Ä—ã–Ω–¥—ã–Ω. –ê–∫-–¢–∞–ª–∞–∞ —Ä–∞–π–æ–Ω—É–Ω–¥–∞ –∫”©–º“Ø—Ä–≥”© –±–∞–π–ª–∞–Ω—ã—à—Ç...</td>\n",
       "      <td>negative</td>\n",
       "      <td>post</td>\n",
       "      <td>–Ω–∞—Ä—ã–Ω–¥—ã–Ω –∞–∫—Ç–∞–ª–∞–∞ —Ä–∞–π–æ–Ω—É–Ω–¥–∞ –∫”©–º“Ø—Ä–≥”© –±–∞–π–ª–∞–Ω—ã—à—Ç—É—É...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>–ñ–µ–≥–∏—á—Ç–µ—Ä 2–¥—É–π–Ω–æ –∂–∞–∫—à—ã–ª—ã–∫ –∫–æ—Ä–±–æ–π –∫–∞–ª–≥—ã–ª–∞ —É–∫—É–º —Ç...</td>\n",
       "      <td>negative</td>\n",
       "      <td>comment</td>\n",
       "      <td>–∂–µ–≥–∏—á—Ç–µ—Ä 2–¥—É–π–Ω–æ –∂–∞–∫—à—ã–ª—ã–∫ –∫–æ—Ä–±–æ–π –∫–∞–ª–≥—ã–ª–∞ —É–∫—É–º —Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3370</th>\n",
       "      <td>–ñ–∞–∫—à—ã –∏—à –∫—ã–ª—ã–ø –∞—Ç—ã–ø—Å—ã–Ω–∞—Ä –±–∏—Ä–æ–∫ –∫–æ–º—É—Ä–¥—É–Ω –±–∞–∞—Å—ã ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>comment</td>\n",
       "      <td>–∂–∞–∫—à—ã –∏—à –∫—ã–ª—ã–ø –∞—Ç—ã–ø—Å—ã–Ω–∞—Ä –∫–æ–º—É—Ä–¥—É–Ω –±–∞–∞—Å—ã –∫–∞–Ω—á–∞–¥–∞–Ω</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>–ê–ª–∞–π  —Ä–∞–π–æ–Ω—É–Ω—É–Ω –°–æ–≥–æ–Ω–¥—É –∞–π—ã–ª—ã–Ω—ã–Ω —Ç—É—Ä–≥—É–Ω–¥–∞—Ä—ã –¢–∞...</td>\n",
       "      <td>negative</td>\n",
       "      <td>post</td>\n",
       "      <td>–∞–ª–∞–π —Ä–∞–π–æ–Ω—É–Ω—É–Ω —Å–æ–≥–æ–Ω–¥—É –∞–π—ã–ª—ã–Ω—ã–Ω —Ç—É—Ä–≥—É–Ω–¥–∞—Ä—ã —Ç–∞–π...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>–ö–∞—Ä–∞-–ö–µ—á–µ–¥–µ–≥–∏, –µ–ª—É–º –∏–ª–∏–∫—Ç–µ–Ω—É—É–¥–µ –ñ—É–º–≥–∞–ª —Ä–∞–π–æ–Ω–¥—É...</td>\n",
       "      <td>negative</td>\n",
       "      <td>post</td>\n",
       "      <td>–∫–∞—Ä–∞–∫–µ—á–µ–¥–µ–≥–∏ –µ–ª—É–º –∏–ª–∏–∫—Ç–µ–Ω—É—É–¥–µ –∂—É–º–≥–∞–ª —Ä–∞–π–æ–Ω–¥—É–∫ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>–ö”©–º“Ø—Ä  —á—ã–∫–∫–∞–Ω –ù–∞—Ä—ã–Ω–¥–∞ –æ—Ç—É–Ω —Ç–∞—Ä—Ç—ã—à –ö–∞—Ä–∞-–ö–µ—á–µ –∫–µ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>post</td>\n",
       "      <td>–∫”©–º“Ø—Ä —á—ã–∫–∫–∞–Ω –Ω–∞—Ä—ã–Ω–¥–∞ –æ—Ç—É–Ω —Ç–∞—Ä—Ç—ã—à –∫–∞—Ä–∞–∫–µ—á–µ –∫–µ–Ω–∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>–ö”©–º“Ø—Ä —Ç–∞—à—ã–≥–∞–Ω –∞–π–¥–æ–æ—á—É–ª–∞—Ä –∏—à —Ç–∞—à—Ç–∞–¥—ã –ë–∏—à–∫–µ–∫ –∂—ã–ª...</td>\n",
       "      <td>negative</td>\n",
       "      <td>post</td>\n",
       "      <td>–∫”©–º“Ø—Ä —Ç–∞—à—ã–≥–∞–Ω –∞–π–¥–æ–æ—á—É–ª–∞—Ä –∏—à —Ç–∞—à—Ç–∞–¥—ã –±–∏—à–∫–µ–∫ –∂—ã–ª...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ –º–∏–Ω–∏—Å—Ç—Ä–∏ –¢.–ò–±—Ä–∞–µ–≤ –ö–∞—Ä–∞-–ö–µ—á–µ –∫–µ–Ω–∏–Ω–µ ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>post</td>\n",
       "      <td>—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ –º–∏–Ω–∏—Å—Ç—Ä–∏ —Ç–∏–±—Ä–∞–µ–≤ –∫–∞—Ä–∞–∫–µ—á–µ –∫–µ–Ω–∏–Ω–µ –±–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>–ò—Ç, –∞–≤–∞–ª–∞–π(.—É—Ä–æ).–±–µ—Ä–µ—Ç –∫–µ—Ä–±–µ–Ω –∂—É—Ä–æ –±–µ—Ä–µ—Ç</td>\n",
       "      <td>negative</td>\n",
       "      <td>comment</td>\n",
       "      <td>–∏—Ç –∞–≤–∞–ª–∞–π—É—Ä–æ–±–µ—Ä–µ—Ç –∫–µ—Ä–±–µ–Ω –∂—É—Ä–æ –±–µ—Ä–µ—Ç</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label   source  \\\n",
       "2632  –ë–∏—à–∫–µ–∫:  —á–µ–∫—Ç”©”© –º–µ–Ω–µ–Ω —Å–∞—Ç—ã–ª–≥–∞–Ω –∞—Ä–∑–∞–Ω –∫”©–º“Ø—Ä –°—É—É...  negative     post   \n",
       "51    –ñ–æ–≥–æ—Ä–∫—É –ö–µ“£–µ—à –ñ–æ–≥–æ—Ä–∫—É —Å–æ—Ç—Ç—É–Ω –º–∏–ª–¥–µ—Ç–∏–Ω –∞—Ç–∫–∞—Ä—ã–ø ...  negative     post   \n",
       "2270  –ë–∏—à–∫–µ–∫–∫–µ! –∞—Ä–∑–∞–Ω –∫”©–º“Ø—Ä –∂–µ—Ç–∫–∏—Ä–∏–ª“Ø“Ø–¥”© ‚Äú–ö–∞—Ä–∞-–ö–µ—á–µ–¥...  positive     post   \n",
       "200   –ñ—É–º–≥–∞–ª —Ä–∞–π–æ–Ω—É–Ω–¥–∞ –∞–∑ –∫–∞–º—Å—ã–∑ —É–π-–±—É–ª–µ–ª–µ—Ä–≥–µ –∂–∞–ª–ø—ã ...  positive     post   \n",
       "888   –ö–∞—Ä–∞-–ö–µ—á–µ–¥–µ–Ω –∫”©–º“Ø—Ä —Ç–∞—Ä—Ç–∫–∞–Ω –∂–µ–∫–µ –∏—à–∫–µ—Ä –∞–π–¥–æ–æ—á—É–ª...  negative     post   \n",
       "2213  –ö”©–º“Ø—Ä, —Ç–∞—à—ã–≥–∞–Ω –∞–π–¥–æ–æ—á—É–ª–∞—Ä –∏—à —Ç–∞—à—Ç–∞–¥—ã –ë–∏—à–∫–µ–∫ –∂—ã...  positive     post   \n",
       "2610  –ù–∞—Ä—ã–Ω–¥—ã–Ω. –ê–∫-–¢–∞–ª–∞–∞ —Ä–∞–π–æ–Ω—É–Ω–¥–∞ –∫”©–º“Ø—Ä–≥”© –±–∞–π–ª–∞–Ω—ã—à—Ç...  negative     post   \n",
       "3222  –ñ–µ–≥–∏—á—Ç–µ—Ä 2–¥—É–π–Ω–æ –∂–∞–∫—à—ã–ª—ã–∫ –∫–æ—Ä–±–æ–π –∫–∞–ª–≥—ã–ª–∞ —É–∫—É–º —Ç...  negative  comment   \n",
       "3370  –ñ–∞–∫—à—ã –∏—à –∫—ã–ª—ã–ø –∞—Ç—ã–ø—Å—ã–Ω–∞—Ä –±–∏—Ä–æ–∫ –∫–æ–º—É—Ä–¥—É–Ω –±–∞–∞—Å—ã ...  positive  comment   \n",
       "1376  –ê–ª–∞–π  —Ä–∞–π–æ–Ω—É–Ω—É–Ω –°–æ–≥–æ–Ω–¥—É –∞–π—ã–ª—ã–Ω—ã–Ω —Ç—É—Ä–≥—É–Ω–¥–∞—Ä—ã –¢–∞...  negative     post   \n",
       "2591  –ö–∞—Ä–∞-–ö–µ—á–µ–¥–µ–≥–∏, –µ–ª—É–º –∏–ª–∏–∫—Ç–µ–Ω—É—É–¥–µ –ñ—É–º–≥–∞–ª —Ä–∞–π–æ–Ω–¥—É...  negative     post   \n",
       "2803  –ö”©–º“Ø—Ä  —á—ã–∫–∫–∞–Ω –ù–∞—Ä—ã–Ω–¥–∞ –æ—Ç—É–Ω —Ç–∞—Ä—Ç—ã—à –ö–∞—Ä–∞-–ö–µ—á–µ –∫–µ...   neutral     post   \n",
       "701   –ö”©–º“Ø—Ä —Ç–∞—à—ã–≥–∞–Ω –∞–π–¥–æ–æ—á—É–ª–∞—Ä –∏—à —Ç–∞—à—Ç–∞–¥—ã –ë–∏—à–∫–µ–∫ –∂—ã–ª...  negative     post   \n",
       "881   –≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ –º–∏–Ω–∏—Å—Ç—Ä–∏ –¢.–ò–±—Ä–∞–µ–≤ –ö–∞—Ä–∞-–ö–µ—á–µ –∫–µ–Ω–∏–Ω–µ ...   neutral     post   \n",
       "4604           –ò—Ç, –∞–≤–∞–ª–∞–π(.—É—Ä–æ).–±–µ—Ä–µ—Ç –∫–µ—Ä–±–µ–Ω –∂—É—Ä–æ –±–µ—Ä–µ—Ç  negative  comment   \n",
       "\n",
       "                                             text_clean  \n",
       "2632  –±–∏—à–∫–µ–∫ —á–µ–∫—Ç”©”© —Å–∞—Ç—ã–ª–≥–∞–Ω –∞—Ä–∑–∞–Ω –∫”©–º“Ø—Ä —Å—É—É–∫ —Ç“Ø—à–∫”©–Ω...  \n",
       "51    –∂–æ–≥–æ—Ä–∫—É –∫–µ“£–µ—à –∂–æ–≥–æ—Ä–∫—É —Å–æ—Ç—Ç—É–Ω –º–∏–ª–¥–µ—Ç–∏–Ω –∞—Ç–∫–∞—Ä—ã–ø ...  \n",
       "2270  –±–∏—à–∫–µ–∫–∫–µ –∞—Ä–∑–∞–Ω –∫”©–º“Ø—Ä –∂–µ—Ç–∫–∏—Ä–∏–ª“Ø“Ø–¥”© –∫–∞—Ä–∞–∫–µ—á–µ–¥–µ–Ω ...  \n",
       "200   –∂—É–º–≥–∞–ª —Ä–∞–π–æ–Ω—É–Ω–¥–∞ –∞–∑ –∫–∞–º—Å—ã–∑ —É–π–±—É–ª–µ–ª–µ—Ä–≥–µ –∂–∞–ª–ø—ã 1...  \n",
       "888   –∫–∞—Ä–∞–∫–µ—á–µ–¥–µ–Ω –∫”©–º“Ø—Ä —Ç–∞—Ä—Ç–∫–∞–Ω –∂–µ–∫–µ –∏—à–∫–µ—Ä –∞–π–¥–æ–æ—á—É–ª–∞...  \n",
       "2213  –∫”©–º“Ø—Ä —Ç–∞—à—ã–≥–∞–Ω –∞–π–¥–æ–æ—á—É–ª–∞—Ä –∏—à —Ç–∞—à—Ç–∞–¥—ã –±–∏—à–∫–µ–∫ –∂—ã–ª...  \n",
       "2610  –Ω–∞—Ä—ã–Ω–¥—ã–Ω –∞–∫—Ç–∞–ª–∞–∞ —Ä–∞–π–æ–Ω—É–Ω–¥–∞ –∫”©–º“Ø—Ä–≥”© –±–∞–π–ª–∞–Ω—ã—à—Ç—É—É...  \n",
       "3222  –∂–µ–≥–∏—á—Ç–µ—Ä 2–¥—É–π–Ω–æ –∂–∞–∫—à—ã–ª—ã–∫ –∫–æ—Ä–±–æ–π –∫–∞–ª–≥—ã–ª–∞ —É–∫—É–º —Ç...  \n",
       "3370   –∂–∞–∫—à—ã –∏—à –∫—ã–ª—ã–ø –∞—Ç—ã–ø—Å—ã–Ω–∞—Ä –∫–æ–º—É—Ä–¥—É–Ω –±–∞–∞—Å—ã –∫–∞–Ω—á–∞–¥–∞–Ω  \n",
       "1376  –∞–ª–∞–π —Ä–∞–π–æ–Ω—É–Ω—É–Ω —Å–æ–≥–æ–Ω–¥—É –∞–π—ã–ª—ã–Ω—ã–Ω —Ç—É—Ä–≥—É–Ω–¥–∞—Ä—ã —Ç–∞–π...  \n",
       "2591  –∫–∞—Ä–∞–∫–µ—á–µ–¥–µ–≥–∏ –µ–ª—É–º –∏–ª–∏–∫—Ç–µ–Ω—É—É–¥–µ –∂—É–º–≥–∞–ª —Ä–∞–π–æ–Ω–¥—É–∫ ...  \n",
       "2803  –∫”©–º“Ø—Ä —á—ã–∫–∫–∞–Ω –Ω–∞—Ä—ã–Ω–¥–∞ –æ—Ç—É–Ω —Ç–∞—Ä—Ç—ã—à –∫–∞—Ä–∞–∫–µ—á–µ –∫–µ–Ω–∏...  \n",
       "701   –∫”©–º“Ø—Ä —Ç–∞—à—ã–≥–∞–Ω –∞–π–¥–æ–æ—á—É–ª–∞—Ä –∏—à —Ç–∞—à—Ç–∞–¥—ã –±–∏—à–∫–µ–∫ –∂—ã–ª...  \n",
       "881   —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ –º–∏–Ω–∏—Å—Ç—Ä–∏ —Ç–∏–±—Ä–∞–µ–≤ –∫–∞—Ä–∞–∫–µ—á–µ –∫–µ–Ω–∏–Ω–µ –±–∞...  \n",
       "4604                –∏—Ç –∞–≤–∞–ª–∞–π—É—Ä–æ–±–µ—Ä–µ—Ç –∫–µ—Ä–±–µ–Ω –∂—É—Ä–æ –±–µ—Ä–µ—Ç  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Step 1: Kyrgyz stopword list (100 words)\n",
    "kyrgyz_stopwords = [\n",
    "    \"–º–µ–Ω\", \"—Å–µ–Ω\", \"–∞–ª\", \"–±–∏–∑\", \"—Å–∏–ª–µ—Ä\", \"–∞–ª–∞—Ä\", \"”©–∑“Ø\", \"–º–µ–Ω–∏–Ω\", \"—Å–µ–Ω–∏–Ω\", \"–∞–Ω—ã–Ω\",\n",
    "    \"–±–∏–∑–¥–∏–Ω\", \"—Å–∏–ª–µ—Ä–¥–∏–Ω\", \"–∞–ª–∞—Ä–¥—ã–Ω\", \"–∫–∏–º\", \"—ç–º–Ω–µ\", \"–∫–∞—á–∞–Ω\", \"–∫–∞–Ω–¥–∞–π\", \"–∫–∞–Ω—á–∞\", \"–∫–∞–π–¥–∞\", \"—ç–º–Ω–µ–≥–µ\",\n",
    "    \"–±—É–ª\", \"—É—à—É–ª\", \"–æ—à–æ–ª\", \"–∞–Ω–¥–∞–Ω\", \"–∞–Ω–¥–∞\", \"—É—à—É–Ω–¥–∞–π\", \"–æ—à–æ–Ω–¥–æ–π\", \"–æ—à–æ–Ω–¥–æ\", \"—É—à–æ–Ω–¥–æ\", \"—É—à—É–Ω—á–∞–ª—ã–∫\",\n",
    "    \"–¥–∞\", \"–¥–µ\", \"–∂–µ\", \"–∂–∞–Ω–∞\", \"–¥–∞–≥—ã\", \"—ç–ª–µ\", \"—ç–º–∏\", \"–∞–Ω–∞–Ω\", \"–±–∏—Ä\", \"—ç–∫–∏\",\n",
    "    \"“Ø—á\", \"—Ç”©—Ä—Ç\", \"–±–µ—à\", \"–æ–Ω\", \"–∂“Ø–∑\", \"–º—ã“£\", \"–∂—ã–ª\", \"–∫“Ø–Ω\", \"–∞–π\", \"—Å–∞–∞—Ç\", \"”©–∑\", \"—Ç–∏–≥–∏\", \n",
    "    \"–º–µ–Ω–µ–Ω\", \"“Ø—á“Ø–Ω\", \"–º–µ–Ω–¥–µ\", \"—Å–µ–Ω–¥–µ\", \"–∞–Ω–¥–∞\", \"–∞–Ω–¥–∞–≥—ã\", \"–º–µ–Ω–¥–µ\", \"—Å–∏–∑\", \"—Å–∏–∑–¥–µ—Ä\", \"—Å–∏–∑–¥–∏–Ω\",\n",
    "    \"–±–æ–ª—É–ø\", \"–±–æ–ª–æ—Ç\", \"–±–æ–ª—Å–æ\", \"–±–æ–ª–≥–æ–Ω—É\", \"–±–æ–ª–±–æ–≥–æ–Ω\", \"—ç–∫–µ–Ω\", \"—ç–∫–µ–Ω–∏–Ω\", \"—ç–∫–µ–Ω—Å–∏“£\", \"—ç–∫–µ–Ω–±–∏–∑\", \"—ç–∫–µ–Ω—Å–∏“£–µ—Ä\",\n",
    "    \"—ç–∫–µ–Ω—Å–∏–∑\", \"–∂–æ–∫\", \"–±–∞—Ä\", \"–∞—Ä\", \"–±–∏—Ä–æ–∫\", \"–∞–Ω—Ç–∫–µ–Ω–∏\", \"–æ—à–æ–Ω–¥—É–∫—Ç–∞–Ω\", \"—Ç–∞—Ä–∞–±—ã–Ω–∞–Ω\", \"—Ç–∞—Ä–∞–ø—Ç–∞–Ω\",\n",
    "    \"—Ç—É—Ä–≥–∞–Ω\", \"–∂–∞—Ç–∫–∞–Ω\", \"–∂”©–Ω“Ø–Ω–¥”©\", \"–∂”©–Ω“Ø–Ω”©–Ω\", \"–±–µ—Ä\", \"–∞–ª–¥—ã\", \"–∞–ª–¥—ã–Ω–∞\", \"–∞—Ä–∫–∞—Å—ã–Ω–∞–Ω\", \"–∏–π–∏–Ω\", \"–∫–∏–π–∏–Ω\", \"–∞–π—Ä—ã–º\",\n",
    "    \"–∫–∏–π–∏–Ω–∫–∏\", \"–±–∞—à–∫–∞\", \"–±–∏—Ä–∏\", \"—ç—á\", \"—ç—á –∫–∏–º\", \"–∂–æ–∫–∫–æ\", \"–∂–æ–∫—Ç—É\", \"–∫–∞—Ç–∞—Ä\", \"–∫—ã–ª–≥–∞–Ω\", \"—á–µ–π–∏–Ω\", \"”©–∫“Ø–ª–¥”©—Ä“Ø\", \n",
    "    \"–±“Ø–≥“Ø–Ω–∫“Ø\", \"–∫–∞—Ä–∞—Ç–∞\", \"–∞—Ç–∞—Ç\", \"–∫–∞–π—Å—ã\", \"–¥–µ–ø\", \"—Å–∏–∑–≥–µ\", \"–¥–µ–π—Ç\", \"–∞\", \"—É—á—É—Ä–¥–∞\", \"—ç—Ö\", \"–∞–π—Ç—ã–ø\", \"–º\"\n",
    "]\n",
    "\n",
    "# Step 2: Define cleaning function\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation/emojis\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)  # remove URLs\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # normalize whitespace\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in kyrgyz_stopwords]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Step 3: Apply cleaning\n",
    "combined_df['text_clean'] = combined_df['text'].apply(clean_text)\n",
    "\n",
    "# Step 4: Remove very short texts (less than 5 words)\n",
    "combined_df['word_count'] = combined_df['text_clean'].apply(lambda x: len(x.split()))\n",
    "filtered_df = combined_df[combined_df['word_count'] >= 5].copy()\n",
    "\n",
    "# Drop helper column\n",
    "filtered_df.drop(columns=['word_count'], inplace=True)\n",
    "\n",
    "# Final shape and preview\n",
    "print(\"Final dataset shape after cleaning:\", filtered_df.shape)\n",
    "filtered_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8093809a-286c-416c-adf9-02ed12e54fee",
   "metadata": {},
   "source": [
    "### 3. Tokenization and Light Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1c6a4bfb-57ac-4476-8669-19cd01945e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3552</th>\n",
       "      <td>–±–æ–ª–±–æ–π—Ç –±–µ–∫–µ—Ä —á—ã–∫–∫–∞–Ω –∫–æ–º—É—Ä–¥—É–Ω –Ω–µ—Å–∏ –∫—ã–º–±–∞—Ç –±–æ–ª—Å—É–Ω</td>\n",
       "      <td>[–±–æ–ª–±–æ–π—Ç, –±–µ–∫–µ—Ä, —á—ã–∫–∫–∞–Ω, –∫–æ–º—É—Ä–¥—É–Ω, –Ω–µ—Å–∏, –∫—ã–º–±–∞...</td>\n",
       "      <td>[–±–æ–ª–±–æ–π—Ç, –±–µ–∫–µ—Ä, —á—ã–∫–∫–∞–Ω, –∫–æ–º—É—Ä, –Ω–µ—Å–∏, –∫—ã–º–±–∞—Ç, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>–∞–ª–∞–π —Ä–∞–π–æ–Ω—É–Ω—É–Ω —Å–æ–≥–æ–Ω–¥—É –∞–π—ã–ª—ã–Ω—ã–Ω —Ç—É—Ä–≥—É–Ω–¥–∞—Ä—ã —Ç–∞–π...</td>\n",
       "      <td>[–∞–ª–∞–π, —Ä–∞–π–æ–Ω—É–Ω—É–Ω, —Å–æ–≥–æ–Ω–¥—É, –∞–π—ã–ª—ã–Ω—ã–Ω, —Ç—É—Ä–≥—É–Ω–¥–∞—Ä...</td>\n",
       "      <td>[–∞–ª–∞–π, —Ä–∞–π–æ–Ω—É, —Å–æ–≥–æ–Ω, –∞–π—ã–ª—ã, —Ç—É—Ä–≥—É–Ω, —Ç–∞–π–≥–∞–∫—Ç–∞—à...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>—É—à—É —É—Å—Ç—É–¥–æ —Ç–æ–π–±–æ—Å —Ç–æ—Ä–¥—É–Ω –∞–π—ã–Ω–∞–Ω –µ–ª–±–∏–∑ –∞–∑–∞–ø —á–µ–∫—Ç–∏</td>\n",
       "      <td>[—É—à—É, —É—Å—Ç—É–¥–æ, —Ç–æ–π–±–æ—Å, —Ç–æ—Ä–¥—É–Ω, –∞–π—ã–Ω–∞–Ω, –µ–ª–±–∏–∑, –∞...</td>\n",
       "      <td>[—É—à—É, —É—Å—Ç—É, —Ç–æ–π–±–æ—Å, —Ç–æ—Ä, –∞–π—ã, –µ–ª–±–∏–∑, –∞–∑–∞–ø, —á–µ–∫—Ç–∏]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>–∫–∞—Ä–∞ –∞–ª—Ç—ã–Ω–¥—ã–Ω ”©–º“Ø—Ä–¥“Ø —É—É—Ä–¥–∞–≥–∞–Ω —Ç“Ø–π—à“Ø–≥“Ø —Ç–∞—à–∫”©–º“Ø—Ä...</td>\n",
       "      <td>[–∫–∞—Ä–∞, –∞–ª—Ç—ã–Ω–¥—ã–Ω, ”©–º“Ø—Ä–¥“Ø, —É—É—Ä–¥–∞–≥–∞–Ω, —Ç“Ø–π—à“Ø–≥“Ø, —Ç–∞...</td>\n",
       "      <td>[–∫–∞—Ä–∞, –∞–ª—Ç—ã–Ω, ”©–º“Ø—Ä, —É—É—Ä–¥–∞, —Ç“Ø–π—à“Ø–≥“Ø, —Ç–∞—à–∫”©–º“Ø—Ä, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>–∂–æ–≥–æ—Ä–∫—É –∫–µ“£–µ—à –∂–æ–≥–æ—Ä–∫—É —Å–æ—Ç—Ç—É–Ω –º–∏–ª–¥–µ—Ç–∏–Ω –∞—Ç–∫–∞—Ä—ã–ø ...</td>\n",
       "      <td>[–∂–æ–≥–æ—Ä–∫—É, –∫–µ“£–µ—à, –∂–æ–≥–æ—Ä–∫—É, —Å–æ—Ç—Ç—É–Ω, –º–∏–ª–¥–µ—Ç–∏–Ω, –∞—Ç...</td>\n",
       "      <td>[–∂–æ–≥–æ—Ä–∫—É, –∫–µ“£–µ—à, –∂–æ–≥–æ—Ä–∫—É, —Å–æ—Ç—Ç—É–Ω, –º–∏–ª–¥–µ—Ç–∏–Ω, –∞—Ç...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_clean  \\\n",
       "3552   –±–æ–ª–±–æ–π—Ç –±–µ–∫–µ—Ä —á—ã–∫–∫–∞–Ω –∫–æ–º—É—Ä–¥—É–Ω –Ω–µ—Å–∏ –∫—ã–º–±–∞—Ç –±–æ–ª—Å—É–Ω   \n",
       "412   –∞–ª–∞–π —Ä–∞–π–æ–Ω—É–Ω—É–Ω —Å–æ–≥–æ–Ω–¥—É –∞–π—ã–ª—ã–Ω—ã–Ω —Ç—É—Ä–≥—É–Ω–¥–∞—Ä—ã —Ç–∞–π...   \n",
       "3052   —É—à—É —É—Å—Ç—É–¥–æ —Ç–æ–π–±–æ—Å —Ç–æ—Ä–¥—É–Ω –∞–π—ã–Ω–∞–Ω –µ–ª–±–∏–∑ –∞–∑–∞–ø —á–µ–∫—Ç–∏   \n",
       "660   –∫–∞—Ä–∞ –∞–ª—Ç—ã–Ω–¥—ã–Ω ”©–º“Ø—Ä–¥“Ø —É—É—Ä–¥–∞–≥–∞–Ω —Ç“Ø–π—à“Ø–≥“Ø —Ç–∞—à–∫”©–º“Ø—Ä...   \n",
       "2706  –∂–æ–≥–æ—Ä–∫—É –∫–µ“£–µ—à –∂–æ–≥–æ—Ä–∫—É —Å–æ—Ç—Ç—É–Ω –º–∏–ª–¥–µ—Ç–∏–Ω –∞—Ç–∫–∞—Ä—ã–ø ...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "3552  [–±–æ–ª–±–æ–π—Ç, –±–µ–∫–µ—Ä, —á—ã–∫–∫–∞–Ω, –∫–æ–º—É—Ä–¥—É–Ω, –Ω–µ—Å–∏, –∫—ã–º–±–∞...   \n",
       "412   [–∞–ª–∞–π, —Ä–∞–π–æ–Ω—É–Ω—É–Ω, —Å–æ–≥–æ–Ω–¥—É, –∞–π—ã–ª—ã–Ω—ã–Ω, —Ç—É—Ä–≥—É–Ω–¥–∞—Ä...   \n",
       "3052  [—É—à—É, —É—Å—Ç—É–¥–æ, —Ç–æ–π–±–æ—Å, —Ç–æ—Ä–¥—É–Ω, –∞–π—ã–Ω–∞–Ω, –µ–ª–±–∏–∑, –∞...   \n",
       "660   [–∫–∞—Ä–∞, –∞–ª—Ç—ã–Ω–¥—ã–Ω, ”©–º“Ø—Ä–¥“Ø, —É—É—Ä–¥–∞–≥–∞–Ω, —Ç“Ø–π—à“Ø–≥“Ø, —Ç–∞...   \n",
       "2706  [–∂–æ–≥–æ—Ä–∫—É, –∫–µ“£–µ—à, –∂–æ–≥–æ—Ä–∫—É, —Å–æ—Ç—Ç—É–Ω, –º–∏–ª–¥–µ—Ç–∏–Ω, –∞—Ç...   \n",
       "\n",
       "                                         tokens_stemmed  \n",
       "3552  [–±–æ–ª–±–æ–π—Ç, –±–µ–∫–µ—Ä, —á—ã–∫–∫–∞–Ω, –∫–æ–º—É—Ä, –Ω–µ—Å–∏, –∫—ã–º–±–∞—Ç, ...  \n",
       "412   [–∞–ª–∞–π, —Ä–∞–π–æ–Ω—É, —Å–æ–≥–æ–Ω, –∞–π—ã–ª—ã, —Ç—É—Ä–≥—É–Ω, —Ç–∞–π–≥–∞–∫—Ç–∞—à...  \n",
       "3052  [—É—à—É, —É—Å—Ç—É, —Ç–æ–π–±–æ—Å, —Ç–æ—Ä, –∞–π—ã, –µ–ª–±–∏–∑, –∞–∑–∞–ø, —á–µ–∫—Ç–∏]  \n",
       "660   [–∫–∞—Ä–∞, –∞–ª—Ç—ã–Ω, ”©–º“Ø—Ä, —É—É—Ä–¥–∞, —Ç“Ø–π—à“Ø–≥“Ø, —Ç–∞—à–∫”©–º“Ø—Ä, ...  \n",
       "2706  [–∂–æ–≥–æ—Ä–∫—É, –∫–µ“£–µ—à, –∂–æ–≥–æ—Ä–∫—É, —Å–æ—Ç—Ç—É–Ω, –º–∏–ª–¥–µ—Ç–∏–Ω, –∞—Ç...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step: Tokenization (whitespace-based)\n",
    "filtered_df['tokens'] = filtered_df['text_clean'].apply(lambda x: x.split())\n",
    "\n",
    "# Optional: Light suffix stripping for common Kyrgyz endings (pseudo-stemming)\n",
    "def pseudo_stem(tokens):\n",
    "    suffixes = [\n",
    "    \"–ª–∞—Ä\", \"–ª–µ—Ä\", \"–ª–æ—Ä\", \"–ª”©—Ä\",\n",
    "    \"—Ç–∞—Ä\", \"—Ç–µ—Ä\", \"—Ç–æ—Ä\", \"—Ç”©—Ä\",\n",
    "    \"–¥–∞—Ä\", \"–¥–µ—Ä\", \"–¥–æ—Ä\", \"–¥”©—Ä\",  # plural\n",
    "    \"–¥—ã–Ω\", \"–¥–∏–Ω\", \"–¥—É–Ω\", \"–¥“Ø–Ω\", \n",
    "    \"—Ç–∞–Ω\", \"—Ç–µ–Ω\", \"–¥–∞–Ω\", \"–¥–µ–Ω\",\n",
    "    \"–Ω–∞–Ω\", \"–Ω–µ–Ω\", \"—Ç–æ–Ω\", \"–¥–æ–Ω\", # ablative case\n",
    "    \"–Ω—ã–Ω\", \"–Ω–∏–Ω\", \"–Ω—É–Ω\", \"–Ω“Ø–Ω\",  # possessive\n",
    "    \"–≥–∞\", \"–≥–µ\", \"–∫–∞\", \"–∫–µ\", \"–≥–æ\", \"–Ω–∞\", \"–≥”©\",     # dative case\n",
    "    \"–¥–∞\", \"–¥–µ\", \"—Ç–∞\", \"—Ç–µ\", \"–¥–æ\", \"—Ç–æ\", \"–¥”©\",    # locative case\n",
    "    \"–¥—ã\", \"–¥–∏\", \"—Ç—É\", \"—Ç“Ø\", \"–¥“Ø\",    # accusative\n",
    "    \"–Ω—ã\", \"–Ω–∏\", \"–Ω—É\", \"–Ω“Ø\", \"–¥—É\",     # object\n",
    "    \"–ª—É—É\", \"–ª“Ø“Ø\", \"–ª—É\", \"–ª“Ø\",    # derivation (e.g., –∂—É–º—É—à+—Ç—É—É)\n",
    "    \"—Å—ã–∑\", \"—Å“Ø–∑\", \"—Å—É–∑\", \"—Å“Ø\",   # negative (e.g., –ø–∞–π–¥–∞—Å—ã–∑)\n",
    "    \"—á—ã–ª\", \"—á–∏–ª\", \"–∫—ã—á\", \"–≥“Ø—á\",  # agentive, group\n",
    "    \"—á—ã–∫\", \"—á–µ–∫\", \"—á“Ø–∫\", \"–∫“Ø—á“Ø–∫\",# diminutives/abstract\n",
    "    \"–º–∞–∫\", \"–º–µ–∫\", \"–ø—ã–∑\",  \"—á—ã\", \"–±–µ–π\", \"–≥–∞–Ω\",   # verbal noun/infinity\n",
    "    \"–¥—ã–∫\", \"–¥–∏–∫\", \"—Ç—É–∫\", \"—Ç“Ø–∫\",  # nominalization\n",
    "    \"—á—ã–ª—ã–∫\", \"—á–∏–ª–∏–∫\", \"–¥–∞–≥—ã\",           # nominalizer\n",
    "    \"–ª”©—Ä–¥“Ø\", \"–¥–∞—Ä—ã\", \"—ã–ø\", \"–æ–ø\", \"–ø–µ–π\"\n",
    "               ]\n",
    "\n",
    "    stemmed = []\n",
    "    for word in tokens:\n",
    "        for suf in suffixes:\n",
    "            if word.endswith(suf) and len(word) > len(suf) + 2:\n",
    "                word = word[: -len(suf)]\n",
    "                break\n",
    "        stemmed.append(word)\n",
    "    return stemmed\n",
    "\n",
    "# Apply optional stemmer\n",
    "filtered_df['tokens_stemmed'] = filtered_df['tokens'].apply(pseudo_stem)\n",
    "\n",
    "# Preview\n",
    "filtered_df[['text_clean', 'tokens', 'tokens_stemmed']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6a3253-d239-4318-9179-0c0f6d434203",
   "metadata": {},
   "source": [
    "### 4. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4859b016-cdb5-4a52-a84e-7ef8e14234a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sentiment labels: ['negative' 'unknown' 'positive' 'neutral']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3681</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638</th>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  label_encoded\n",
       "1359  negative              0\n",
       "2419  positive              2\n",
       "3325  negative              0\n",
       "3984  negative              0\n",
       "3594  negative              0\n",
       "1334  negative              0\n",
       "3681  negative              0\n",
       "4639  negative              0\n",
       "1125  negative              0\n",
       "4519  negative              0\n",
       "653   negative              0\n",
       "2141  positive              2\n",
       "739   positive              2\n",
       "1221  positive              2\n",
       "3638  positive              2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique labels\n",
    "print(\"Unique sentiment labels:\", filtered_df['label'].unique())\n",
    "\n",
    "# Remove rows with unknown label\n",
    "filtered_df = filtered_df[filtered_df['label'] != 'unknown'].copy()\n",
    "\n",
    "# Map labels to integers\n",
    "label_mapping = {\n",
    "    'negative': 0,\n",
    "    'neutral': 1,\n",
    "    'positive': 2\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "filtered_df['label_encoded'] = filtered_df['label'].map(label_mapping)\n",
    "\n",
    "# Verify\n",
    "filtered_df[['label', 'label_encoded']].sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a7844203-8363-4f37-8a14-d7cb4145f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_df.to_csv(\"../data/filtered_df_stemmed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a2198-284e-47c4-9cb4-6c433472b6c1",
   "metadata": {},
   "source": [
    "### 5. Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5851b3c7-2b60-4773-909f-c6d9b017e1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_encoded\n",
       "0    0.592968\n",
       "2    0.294118\n",
       "1    0.112914\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['label_encoded'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a722ffff-c5e1-4231-8025-da03e6cdd018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "972eb563-705d-4ad7-aef7-06332d15fad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5621436716077537, 1: 2.9520958083832336, 2: 1.1333333333333333}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "y = filtered_df['label_encoded']\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "\n",
    "print(dict(enumerate(class_weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90750d-744f-4cab-8615-8e52a0e01102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
